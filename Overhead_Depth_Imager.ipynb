{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9e9f6e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Estimated table height z=1.081 m\n",
      "Using centroid Z = 1.181 m\n",
      "Rendering overhead image and depth map...\n",
      "Largest contour area: 341500.0\n",
      "Image corner 0: pixel [390. 869.] → world [-1.10000002 -0.40000001]\n",
      "Image corner 1: pixel [809. 869.] → world [-0.69999999 -0.40000001]\n",
      "Image corner 2: pixel [809.  30.] → world [-0.69999999  0.40000001]\n",
      "Image corner 3: pixel [390.  30.] → world [-1.10000002  0.40000001]\n",
      "✅  Homography calibration successful.\n",
      "Detecting colors...\n",
      "\n",
      "red_box: found 3 object(s)\n",
      "  red_box[0]  X=-0.7432, Y=0.2086, Z=1.1810\n",
      "  red_box[1]  X=-0.9000, Y=-0.2089, Z=1.1810\n",
      "  red_box[2]  X=-0.9000, Y=-0.0004, Z=1.1810\n",
      "\n",
      "green_box: found 1 object(s)\n",
      "  green_box[0]  X=-1.0038, Y=-0.1041, Z=1.1810\n",
      "\n",
      "blue_box: found 1 object(s)\n",
      "  blue_box[0]  X=-1.0035, Y=0.3109, Z=1.1810\n",
      "Saved: overhead_rgb_annotated.png\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# overhead_multicolor_pixel_to_world_calibrated.py\n",
    "# Requirements: pip install mujoco glfw PyOpenGL pillow numpy opencv-python\n",
    "\n",
    "import numpy as np\n",
    "import mujoco as mj\n",
    "from mujoco.glfw import glfw\n",
    "import OpenGL.GL as gl\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "# --------- User config ---------\n",
    "XML_PATH = \"franka_panda_w_objs.xml\"\n",
    "CAM_NAME = \"overhead_cam\"\n",
    "WINDOW_SIZE = (1200, 900)\n",
    "USE_CV_CONVENTION = True\n",
    "\n",
    "Z_TABLE_FALLBACK = 0.0    # fallback table height (m)\n",
    "Z_ABOVE_TABLE = 0.10        # offset above table (m)\n",
    "USE_HOMOGRAPHY_CALIBRATION = True   # <-- enable table-based mapping\n",
    "\n",
    "COLOR_CLASSES = {\n",
    "    \"red_box\":   {\"ref_rgb\": (255, 0, 0),   \"tol\": 0},\n",
    "    \"green_box\": {\"ref_rgb\": (0, 255, 0),   \"tol\": 0},\n",
    "    \"blue_box\":  {\"ref_rgb\": (0, 0, 255),   \"tol\": 0},\n",
    "}\n",
    "\n",
    "GRID = 48\n",
    "MIN_PIXELS = 80\n",
    "# --------------------------------\n",
    "\n",
    "\n",
    "def intrinsics_from_fovy(fovy_deg, width, height):\n",
    "    H, W = height, width\n",
    "    fovy_rad = np.deg2rad(float(fovy_deg))\n",
    "    fy = H / (2.0 * np.tan(fovy_rad / 2.0))\n",
    "    fx = fy\n",
    "    cx = (W - 1) / 2.0\n",
    "    cy = (H - 1) / 2.0\n",
    "    return fx, fy, cx, cy\n",
    "\n",
    "\n",
    "def pixel_to_world_from_depth(u, v, depth_m, W, H, fovy_deg, cam_pos, cam_xmat, use_cv=True):\n",
    "    fx, fy, cx, cy = intrinsics_from_fovy(fovy_deg, W, H)\n",
    "    x = (u - cx) / fx\n",
    "    y = (v - cy) / fy\n",
    "    z = 1.0\n",
    "    d_cam_cv = np.array([x, y, z], dtype=np.float32)\n",
    "    d_cam_cv /= np.linalg.norm(d_cam_cv)\n",
    "    if use_cv:\n",
    "        d_cam_mj = np.array([d_cam_cv[0], -d_cam_cv[1], -d_cam_cv[2]], dtype=np.float32)\n",
    "    else:\n",
    "        d_cam_mj = np.array([x, y, -1.0], dtype=np.float32)\n",
    "    R = cam_xmat.reshape(3, 3)\n",
    "    p_world = cam_pos + (R.T @ d_cam_mj) * depth_m\n",
    "    return p_world\n",
    "\n",
    "\n",
    "def mask_from_ref_hsv(rgb, ref_rgb, hue_tol=15, sat_min=10, val_min=10):\n",
    "    \"\"\"\n",
    "    Create mask by comparing image to a reference RGB color in HSV space,\n",
    "    allowing hue tolerance and thresholds on saturation and value for darker pixels.\n",
    "\n",
    "    Args:\n",
    "        rgb: (H, W, 3) uint8 image in RGB.\n",
    "        ref_rgb: (3,) reference RGB color tuple (0-255).\n",
    "        hue_tol: int tolerance around hue (in degrees, 0-180 in OpenCV).\n",
    "        sat_min: int minimum saturation (0-255).\n",
    "        val_min: int minimum value/brightness (0-255).\n",
    "\n",
    "    Returns:\n",
    "        mask: (H, W) boolean mask where pixels match color within tolerance.\n",
    "    \"\"\"\n",
    "    # Convert image to HSV\n",
    "    hsv_img = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Convert reference color to HSV (single pixel)\n",
    "    ref_bgr = np.uint8([[ref_rgb[::-1]]])  # RGB->BGR for cv2\n",
    "    ref_hsv = cv2.cvtColor(ref_bgr, cv2.COLOR_BGR2HSV)[0,0]\n",
    "\n",
    "    h_ref, s_ref, v_ref = ref_hsv\n",
    "\n",
    "    # Hue lower and upper bounds, wrapping around 180 if needed\n",
    "    lower_h = (h_ref - hue_tol) % 180\n",
    "    upper_h = (h_ref + hue_tol) % 180\n",
    "\n",
    "    if lower_h <= upper_h:\n",
    "        hue_mask = (hsv_img[:,:,0] >= lower_h) & (hsv_img[:,:,0] <= upper_h)\n",
    "    else:\n",
    "        # Wrap-around case\n",
    "        hue_mask = (hsv_img[:,:,0] >= lower_h) | (hsv_img[:,:,0] <= upper_h)\n",
    "\n",
    "    sat_mask = hsv_img[:,:,1] >= sat_min\n",
    "    val_mask = hsv_img[:,:,2] >= val_min\n",
    "\n",
    "    mask = hue_mask & sat_mask & val_mask\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "def centroids_from_mask_grid(mask, grid=48, min_pixels=80):\n",
    "    H, W = mask.shape\n",
    "    ys, xs = np.nonzero(mask)\n",
    "    if ys.size == 0:\n",
    "        return []\n",
    "    gx = (xs * grid) // W\n",
    "    gy = (ys * grid) // H\n",
    "    gx = gx.clip(0, grid - 1)\n",
    "    gy = gy.clip(0, grid - 1)\n",
    "    bin_keys = (gy * grid + gx).astype(np.int32)\n",
    "    order = np.argsort(bin_keys)\n",
    "    bin_keys_sorted = bin_keys[order]\n",
    "    unique_bins, first_idx, counts = np.unique(bin_keys_sorted, return_index=True, return_counts=True)\n",
    "    keep_mask = counts >= int(min_pixels)\n",
    "    if not np.any(keep_mask):\n",
    "        return [(float(xs.mean()), float(ys.mean()))]\n",
    "    kept_bins = unique_bins[keep_mask]\n",
    "    kept_first = first_idx[keep_mask]\n",
    "    kept_counts = counts[keep_mask]\n",
    "    bin_to_slice = {int(b): (int(f), int(f + c)) for b, f, c in zip(kept_bins, kept_first, kept_counts)}\n",
    "    cell_set = set([(int(b) // grid, int(b) % grid) for b in kept_bins])\n",
    "    visited, components = set(), []\n",
    "    for cell in cell_set:\n",
    "        if cell in visited:\n",
    "            continue\n",
    "        comp, queue = [], [cell]\n",
    "        visited.add(cell)\n",
    "        while queue:\n",
    "            cy, cx = queue.pop()\n",
    "            comp.append((cy, cx))\n",
    "            for ny, nx in ((cy - 1, cx), (cy + 1, cx), (cy, cx - 1), (cy, cx + 1)):\n",
    "                if 0 <= ny < grid and 0 <= nx < grid and (ny, nx) in cell_set and (ny, nx) not in visited:\n",
    "                    visited.add((ny, nx))\n",
    "                    queue.append((ny, nx))\n",
    "        components.append(comp)\n",
    "    centroids = []\n",
    "    for comp in components:\n",
    "        comp_indices = []\n",
    "        for (cy, cx) in comp:\n",
    "            b = cy * grid + cx\n",
    "            if b in bin_to_slice:\n",
    "                lo, hi = bin_to_slice[b]\n",
    "                comp_indices.append(order[lo:hi])\n",
    "        if comp_indices:\n",
    "            comp_idx = np.concatenate(comp_indices, axis=0)\n",
    "            u = float(xs[comp_idx].mean())\n",
    "            v = float(ys[comp_idx].mean())\n",
    "            centroids.append((u, v))\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def detect_colors_centroids(rgb, color_classes, grid=48, min_pixels=80):\n",
    "    results = {}\n",
    "    for name, spec in color_classes.items():\n",
    "        ref, tol = spec[\"ref_rgb\"], int(spec.get(\"tol\", 60))\n",
    "        mask = mask_from_ref_hsv(rgb, ref, tol)\n",
    "        cents = centroids_from_mask_grid(mask, grid=grid, min_pixels=min_pixels)\n",
    "        results[name] = cents\n",
    "    return results\n",
    "\n",
    "\n",
    "def estimate_table_z_from_known_geom(model, data):\n",
    "    candidates = [\"box_geom\", \"box_geom2\", \"box_geom3\"]\n",
    "    for gname in candidates:\n",
    "        gid = mj.mj_name2id(model, mj.mjtObj.mjOBJ_GEOM, gname)\n",
    "        if gid >= 0:\n",
    "            mj.mj_forward(model, data)\n",
    "            z_center = float(data.geom_xpos[gid, 2])\n",
    "            z_half = float(model.geom_size[gid, 2])\n",
    "            return z_center - z_half\n",
    "    return None\n",
    "\n",
    "\n",
    "def render_and_capture(model, data, cam_name, window_size):\n",
    "    W, H = window_size\n",
    "    if not glfw.init():\n",
    "        raise RuntimeError(\"Failed to initialize GLFW\")\n",
    "    glfw.window_hint(glfw.VISIBLE, glfw.TRUE)\n",
    "    window = glfw.create_window(W, H, \"Overhead Capture\", None, None)\n",
    "    glfw.make_context_current(window)\n",
    "    glfw.swap_interval(1)\n",
    "\n",
    "    model.vis.map.znear, model.vis.map.zfar = 0.055, 5.0\n",
    "\n",
    "    cam = mj.MjvCamera()\n",
    "    opt = mj.MjvOption()\n",
    "    mj.mjv_defaultCamera(cam)\n",
    "    mj.mjv_defaultOption(opt)\n",
    "    scene = mj.MjvScene(model, maxgeom=10000)\n",
    "    context = mj.MjrContext(model, mj.mjtFontScale.mjFONTSCALE_150.value)\n",
    "\n",
    "    cam_id = mj.mj_name2id(model, mj.mjtObj.mjOBJ_CAMERA, cam_name)\n",
    "    if cam_id < 0:\n",
    "        raise ValueError(f\"Camera '{cam_name}' not found\")\n",
    "\n",
    "    cam.type = mj.mjtCamera.mjCAMERA_FIXED\n",
    "    cam.fixedcamid = cam_id\n",
    "    mj.mj_forward(model, data)\n",
    "\n",
    "    fb_w, fb_h = glfw.get_framebuffer_size(window)\n",
    "    viewport = mj.MjrRect(0, 0, fb_w, fb_h)\n",
    "    mj.mjv_updateScene(model, data, opt, None, cam, mj.mjtCatBit.mjCAT_ALL.value, scene)\n",
    "    mj.mjr_render(viewport, scene, context)\n",
    "\n",
    "    gl.glPixelStorei(gl.GL_PACK_ALIGNMENT, 1)\n",
    "\n",
    "    rgba_bytes = gl.glReadPixels(0, 0, fb_w, fb_h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE)\n",
    "    rgba = np.frombuffer(rgba_bytes, dtype=np.uint8).reshape(fb_h, fb_w, 4)\n",
    "    rgb = np.flip(rgba[:, :, :3], axis=0).copy()\n",
    "\n",
    "    depth_bytes = gl.glReadPixels(0, 0, fb_w, fb_h, gl.GL_DEPTH_COMPONENT, gl.GL_FLOAT)\n",
    "    depth = np.frombuffer(depth_bytes, dtype=np.float32).reshape(fb_h, fb_w)\n",
    "    depth = np.flip(depth, axis=0)\n",
    "\n",
    "    znear, zfar = model.vis.map.znear, model.vis.map.zfar\n",
    "    linear_depth = 2.0 * znear * zfar / (zfar + znear - (2.0 * depth - 1.0) * (zfar - znear))\n",
    "\n",
    "    fovy_deg = float(model.cam_fovy[cam_id])\n",
    "    cam_pos = data.cam_xpos[cam_id].copy()\n",
    "    cam_xmat = data.cam_xmat[cam_id].copy()\n",
    "\n",
    "    glfw.destroy_window(window)\n",
    "    glfw.terminate()\n",
    "    return rgb, linear_depth, fovy_deg, cam_pos, cam_xmat\n",
    "\n",
    "def order_corners(corners):\n",
    "    # corners is (4, 2)\n",
    "    # Step 1: sort by y (vertical)\n",
    "    sorted_by_y = corners[np.argsort(corners[:,1]), :]\n",
    "    top_two = sorted_by_y[:2, :]\n",
    "    bottom_two = sorted_by_y[2:, :]\n",
    "\n",
    "    # Step 2: among top two, sort by x (horizontal)\n",
    "    top_left, top_right = top_two[np.argsort(top_two[:,0]), :]\n",
    "    # Step 3: among bottom two, sort by x (horizontal)\n",
    "    bottom_left, bottom_right = bottom_two[np.argsort(bottom_two[:,0]), :]\n",
    "\n",
    "    # Return in order: bottom-left, bottom-right, top-right, top-left\n",
    "    return np.array([bottom_left, bottom_right, top_right, top_left], dtype=np.float32)\n",
    "\n",
    "\n",
    "def calibrate_homography_from_table(rgb, model, data):\n",
    "    pos = np.array([-0.9, 0.0])\n",
    "    size = np.array([0.2, 0.4])\n",
    "    corners_world = np.array([\n",
    "        [pos[0]-size[0], pos[1]-size[1]],\n",
    "        [pos[0]+size[0], pos[1]-size[1]],\n",
    "        [pos[0]+size[0], pos[1]+size[1]],\n",
    "        [pos[0]-size[0], pos[1]+size[1]],\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    _, mask = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)  # lower threshold\n",
    "\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    cv2.imwrite(\"table_mask.png\", mask)  # save to check visually\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        print(\"⚠️  Table contour not found — homography disabled.\")\n",
    "        return None\n",
    "\n",
    "    largest = max(contours, key=cv2.contourArea)\n",
    "    print(f\"Largest contour area: {cv2.contourArea(largest)}\")\n",
    "\n",
    "    epsilon = 0.05 * cv2.arcLength(largest, True)\n",
    "    approx = cv2.approxPolyDP(largest, epsilon, True)\n",
    "\n",
    "    if len(approx) != 4:\n",
    "        print(f\"⚠️  Table contour not quadrilateral (found {len(approx)} corners) — trying minAreaRect fallback.\")\n",
    "        rect = cv2.minAreaRect(largest)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        approx = np.int0(box)\n",
    "        if len(approx) != 4:\n",
    "            print(\"⚠️  Fallback contour also not quadrilateral — homography disabled.\")\n",
    "            return None\n",
    "\n",
    "    corners_px = np.array([p[0] if p.shape == (1,2) else p for p in approx], dtype=np.float32)\n",
    "\n",
    "    corners_px = order_corners(corners_px)\n",
    "\n",
    "\n",
    "    H, _ = cv2.findHomography(corners_px, corners_world)\n",
    "    for i, pt in enumerate(corners_px):\n",
    "        uv1 = np.array([pt[0], pt[1], 1.0])\n",
    "        XY1 = H @ uv1\n",
    "        XY1 /= XY1[2]\n",
    "        print(f\"Image corner {i}: pixel {pt} → world {XY1[:2]}\")\n",
    "\n",
    "    print(\"✅  Homography calibration successful.\")\n",
    "    return H\n",
    "\n",
    "\n",
    "\n",
    "def draw_annotations(rgb, original_detections, shifted_detections, color_classes, radius=8):\n",
    "    img = Image.fromarray(rgb)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for cname, cents in original_detections.items():\n",
    "        ref = color_classes[cname][\"ref_rgb\"]\n",
    "        for i, (u, v) in enumerate(cents):\n",
    "            # Draw original centroid in class color, bigger circle\n",
    "            draw.ellipse((u-radius, v-radius, u+radius, v+radius), outline=ref, width=3)\n",
    "            draw.text((u+radius+2, v-radius-2), f\"{cname}[{i}]\", fill=ref)\n",
    "\n",
    "    for cname, cents in shifted_detections.items():\n",
    "        ref = color_classes[cname][\"ref_rgb\"]\n",
    "        for i, (u, v, _) in enumerate(cents):\n",
    "            # Draw shifted centroid in class color, smaller circle, dashed outline (simulate)\n",
    "            r = radius // 2\n",
    "            # Different style: here just thinner and smaller circle in same color\n",
    "            draw.ellipse((u-r, v-r, u+r, v+r), outline=ref, width=1)\n",
    "            # Optionally add a marker (e.g., a dot) inside\n",
    "            draw.point((u, v), fill=ref)\n",
    "\n",
    "    return np.array(img)\n",
    "\n",
    "def main():\n",
    "    print(\"Loading model...\")\n",
    "    model = mj.MjModel.from_xml_path(XML_PATH)\n",
    "    data = mj.MjData(model)\n",
    "\n",
    "    z_table = estimate_table_z_from_known_geom(model, data)\n",
    "    if z_table is None:\n",
    "        z_table = Z_TABLE_FALLBACK\n",
    "        print(f\"Table Height Estimation Failed!\")\n",
    "    else:\n",
    "        print(f\"Estimated table height z={z_table:.3f} m\")\n",
    "\n",
    "    z_target = z_table + Z_ABOVE_TABLE\n",
    "    print(f\"Using centroid Z = {z_target:.3f} m\")\n",
    "\n",
    "    print(\"Rendering overhead image and depth map...\")\n",
    "    rgb, depth_map, fovy_deg, cam_pos, cam_xmat = render_and_capture(model, data, CAM_NAME, WINDOW_SIZE)\n",
    "    Image.fromarray(rgb).save(\"overhead_rgb.png\")\n",
    "\n",
    "    H_homography = calibrate_homography_from_table(rgb, model, data) if USE_HOMOGRAPHY_CALIBRATION else None\n",
    "\n",
    "    print(\"Detecting colors...\")\n",
    "    detections = detect_colors_centroids(rgb, COLOR_CLASSES, grid=GRID, min_pixels=MIN_PIXELS)\n",
    "    results_by_color_shifted = {}\n",
    "    results_by_color_original = detections\n",
    "    H, W, _ = rgb.shape\n",
    "\n",
    "    for cname, cents in detections.items():\n",
    "        pts_world_shifted = []\n",
    "        for (u, v) in cents:\n",
    "            if H_homography is not None:\n",
    "                uv1 = np.array([u, v, 1.0])\n",
    "                XY1 = H_homography @ uv1\n",
    "                XY1 /= XY1[2]\n",
    "                X, Y = XY1[0], XY1[1]\n",
    "                P = np.array([X, Y, z_target])\n",
    "            else:\n",
    "                u_i, v_i = int(round(u)), int(round(v))\n",
    "                if 0 <= v_i < depth_map.shape[0] and 0 <= u_i < depth_map.shape[1]:\n",
    "                    depth_m = float(depth_map[v_i, u_i])\n",
    "                    if np.isfinite(depth_m) and depth_m > 0:\n",
    "                        P = pixel_to_world_from_depth(\n",
    "                            u, v, depth_m, W, H, fovy_deg,\n",
    "                            cam_pos=cam_pos, cam_xmat=cam_xmat, use_cv=USE_CV_CONVENTION)\n",
    "                        P[2] = z_target\n",
    "                    else:\n",
    "                        continue  # skip invalid depth point\n",
    "                else:\n",
    "                    continue  # skip out-of-bounds\n",
    "\n",
    "            table_center = np.array([-0.9, 0.0])  # your table center (x,y)\n",
    "            weight = 0.1  # tune this between 0 and 1 as you like\n",
    "\n",
    "            P_xy = P[:2]\n",
    "            shifted_xy = (1 - weight) * P_xy + weight * table_center\n",
    "            P_shifted = np.array([shifted_xy[0], shifted_xy[1], P[2]])\n",
    "\n",
    "            pts_world_shifted.append(P_shifted)\n",
    "\n",
    "        results_by_color_shifted[cname] = pts_world_shifted\n",
    "\n",
    "    for cname, pts in results_by_color_shifted.items():\n",
    "        print(f\"\\n{cname}: found {len(pts)} object(s)\")\n",
    "        for i, P in enumerate(pts):\n",
    "            print(f\"  {cname}[{i}]  X={P[0]:.4f}, Y={P[1]:.4f}, Z={P[2]:.4f}\")\n",
    "\n",
    "    annotated = draw_annotations(rgb, results_by_color_original, results_by_color_shifted, COLOR_CLASSES)\n",
    "    Image.fromarray(annotated).save(\"overhead_rgb_annotated.png\")\n",
    "    print(\"Saved: overhead_rgb_annotated.png\\nDone.\")\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
